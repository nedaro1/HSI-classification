{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef, hamming_loss\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping#, ReduceLROnPlateau\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('../datasets/P_M_S3_Remove15.mat')  #Rand_3pairs_multi.mat \n",
    "\n",
    "X = data['X_all'] # Input (Reflectance Spectrum)\n",
    "Y_multi = data['Y_multi_all'] # Output Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data to training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y_multi, test_size=0.2, random_state=1) #0.6\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1) #0.6\n",
    "\n",
    "## Maybe I need to normalize the data\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "#X_train /= 4095\n",
    "#X_val /= 4095\n",
    "#X_test /= 4095"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=226, activation='sigmoid'))\n",
    "#model.add(Dense(128, input_dim=221))\n",
    "#model.add(Dense(64, input_dim=221))#, activation='sigmoid'))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "#model.add(Dense(64, activation='sigmoid'))\n",
    "model.add(Dense(32))#, activation='sigmoid'))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Dense(16))\n",
    "model.add(Dense(Y_multi.shape[1], activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_checker = EarlyStopping(monitor='val_acc', patience=5, verbose=0, mode='auto')\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10560 samples, validate on 2640 samples\n",
      "Epoch 1/100\n",
      "10560/10560 [==============================] - 3s 278us/step - loss: 0.2912 - acc: 0.8728 - val_loss: 0.1368 - val_acc: 0.9479\n",
      "Epoch 2/100\n",
      "10560/10560 [==============================] - 2s 217us/step - loss: 0.0760 - acc: 0.9763 - val_loss: 0.0344 - val_acc: 0.9941\n",
      "Epoch 3/100\n",
      "10560/10560 [==============================] - 2s 225us/step - loss: 0.0205 - acc: 0.9968 - val_loss: 0.0105 - val_acc: 0.9987\n",
      "Epoch 4/100\n",
      "10560/10560 [==============================] - 2s 226us/step - loss: 0.0088 - acc: 0.9983 - val_loss: 0.0065 - val_acc: 0.9986\n",
      "Epoch 5/100\n",
      "10560/10560 [==============================] - 3s 240us/step - loss: 0.0064 - acc: 0.9984 - val_loss: 0.0051 - val_acc: 0.9993\n",
      "Epoch 6/100\n",
      "10560/10560 [==============================] - 3s 248us/step - loss: 0.0049 - acc: 0.9987 - val_loss: 0.0036 - val_acc: 0.9997\n",
      "Epoch 7/100\n",
      "10560/10560 [==============================] - 3s 247us/step - loss: 0.0042 - acc: 0.9989 - val_loss: 0.0031 - val_acc: 0.9995\n",
      "Epoch 8/100\n",
      "10560/10560 [==============================] - 3s 239us/step - loss: 0.0035 - acc: 0.9991 - val_loss: 0.0023 - val_acc: 0.9996\n",
      "Epoch 9/100\n",
      "10560/10560 [==============================] - 2s 232us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.0047 - val_acc: 0.9989\n",
      "Epoch 10/100\n",
      "10560/10560 [==============================] - 3s 240us/step - loss: 0.0032 - acc: 0.9990 - val_loss: 0.0026 - val_acc: 0.9994\n",
      "Epoch 11/100\n",
      "10560/10560 [==============================] - 3s 250us/step - loss: 0.0057 - acc: 0.9983 - val_loss: 0.0049 - val_acc: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe6ec098f60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epoch = 100\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=nb_epoch, batch_size=32, verbose=1, validation_data=(X_val, y_val), callbacks=[early_checker]) #early_checker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.00328477535408\n",
      "Test accuracy: 0.99929293199\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300/3300 [==============================] - 0s 47us/step\n",
      "[ 0.1   0.1   0.1   0.1   0.45  0.1   0.1   0.1   0.85]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# calculate predictions\n",
    "predictions = model.predict(X_test)\n",
    "\"\"\"\n",
    "predictions = model.predict_proba(X_test)\n",
    "threshold = np.arange(0.1,0.9,0.05)\n",
    "\n",
    "acc = []\n",
    "accuracies = []\n",
    "best_threshold = np.zeros(predictions.shape[1])\n",
    "for i in range(predictions.shape[1]):\n",
    "    acc = []\n",
    "    y_prob = np.array(predictions[:,i])\n",
    "    for j in threshold:\n",
    "        y_pred = [1 if prob>=j else 0 for prob in y_prob]\n",
    "        acc.append( matthews_corrcoef(y_test[:,i],y_pred))\n",
    "    acc   = np.array(acc)\n",
    "    index = np.where(acc==acc.max())\n",
    "    accuracies.append(acc.max())\n",
    "    best_threshold[i] = threshold[index[0][0]]\n",
    "\n",
    "\n",
    "print (best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00037037037037037035\n",
      "0.9966666666666667 3289 3300\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.array([[1 if predictions[i,j]>=best_threshold[j] else 0 for j in range(y_test.shape[1])] for i in range(len(y_test))])\n",
    "print (hamming_loss(y_test,y_pred))\n",
    "\n",
    "total_correctly_predicted = len([i for i in range(len(y_test)) if (y_test[i]==y_pred[i]).sum() == Y_multi.shape[1]])\n",
    "print (float(total_correctly_predicted)/X_test.shape[0], total_correctly_predicted, X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2640/2640 [==============================] - 0s 40us/step\n",
      "[ 0.1   0.1   0.1   0.1   0.5   0.1   0.1   0.1   0.65]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# calculate predictions\n",
    "predictions = model.predict(X_test)\n",
    "\"\"\"\n",
    "## Using validation to find the best thresholds\n",
    "\n",
    "predictions_val = model.predict_proba(X_val)\n",
    "threshold_val = np.arange(0.1,0.9,0.05)\n",
    "\n",
    "acc_val = []\n",
    "accuracies_val = []\n",
    "best_threshold_val = np.zeros(predictions_val.shape[1])\n",
    "for i in range(predictions_val.shape[1]):\n",
    "    acc_val = []\n",
    "    y_prob_val = np.array(predictions_val[:,i])\n",
    "    for j in threshold_val:\n",
    "        y_pred_val = [1 if prob>=j else 0 for prob in y_prob_val]\n",
    "        acc_val.append( matthews_corrcoef(y_val[:,i],y_pred_val))\n",
    "    acc_val   = np.array(acc_val)\n",
    "    index = np.where(acc_val==acc_val.max())\n",
    "    accuracies_val.append(acc_val.max())\n",
    "    best_threshold_val[i] = threshold_val[index[0][0]]\n",
    "\n",
    "\n",
    "print (best_threshold_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00047138047138047136\n",
      "0.9957575757575757 3286 3300\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = np.array([[1 if predictions[i,j]>=best_threshold_val[j] else 0 for j in range(y_test.shape[1])] for i in range(len(y_test))])\n",
    "\n",
    "print (hamming_loss(y_test,y_pred2))\n",
    "\n",
    "total_correctly_predicted2 = len([i for i in range(len(y_test)) if (y_test[i]==y_pred2[i]).sum() == Y_multi.shape[1]])\n",
    "\n",
    "print (float(total_correctly_predicted2)/X_test.shape[0], total_correctly_predicted2, X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Reading files\n",
    "data = scipy.io.loadmat('../datasets/Manu_L_Box_Sm.mat')  #Islamic_img2.mat\n",
    "\n",
    "X_real = data['smooth_Im'] #img_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114144/114144 [==============================] - 4s 36us/step\n"
     ]
    }
   ],
   "source": [
    "predictions_real = model.predict_proba(np.transpose(X_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = Y_multi.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_real = np.array([[1 if predictions_real[i,j]>=best_threshold[j] else 0 for j in range(num_classes)] for i in range(X_real.shape[1])])\n",
    "y_pred2_real = np.array([[1 if predictions_real[i,j]>=best_threshold_val[j] else 0 for j in range(num_classes)] for i in range(X_real.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.io.savemat('../datasets/Manuscript/P_M/y_pred_manu_L_box_sm.mat', mdict={'y_pred_real': y_pred_real})\n",
    "scipy.io.savemat('../datasets/Manuscript/P_M/y_pred2_manu_L_box_sm.mat', mdict={'y_pred2_real': y_pred2_real} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
