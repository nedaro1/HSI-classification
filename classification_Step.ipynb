{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import linear_model, svm\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('../datasets/P+M+Islamic.mat')  #Data_DL_F.mat\n",
    "\n",
    "X = data['X_all'] # Input (Reflectance Spectra)\n",
    "Y = data['Y_all'] # Labels\n",
    "\n",
    "Y = Y-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data to training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1, stratify=Y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1, stratify=y_train)\n",
    "\n",
    "## Maybe I need to normalize the data\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "#X_train /= 4095\n",
    "#X_val /= 4095\n",
    "#X_test /= 4095"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the labels (one hot vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = np.max(Y)+1 \n",
    "# Convert 1-dimensional class arrays to n-dimensional class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_val = np_utils.to_categorical(y_val, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=221, activation='sigmoid'))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(32))#, activation='tanh'))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Dense(16))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "# Avoid overfitting\n",
    "early_checker = EarlyStopping(monitor='val_acc', patience=5, verbose=0, mode='auto')\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 832 samples, validate on 208 samples\n",
      "Epoch 1/100\n",
      "832/832 [==============================] - 1s 1ms/step - loss: 2.4467 - acc: 0.1683 - val_loss: 2.2282 - val_acc: 0.2308\n",
      "Epoch 2/100\n",
      "832/832 [==============================] - 0s 265us/step - loss: 1.9547 - acc: 0.3425 - val_loss: 1.5846 - val_acc: 0.5529\n",
      "Epoch 3/100\n",
      "832/832 [==============================] - 0s 241us/step - loss: 1.3169 - acc: 0.5721 - val_loss: 1.0338 - val_acc: 0.7019\n",
      "Epoch 4/100\n",
      "832/832 [==============================] - 0s 254us/step - loss: 0.8614 - acc: 0.7752 - val_loss: 0.6925 - val_acc: 0.8077\n",
      "Epoch 5/100\n",
      "832/832 [==============================] - 0s 238us/step - loss: 0.5439 - acc: 0.9014 - val_loss: 0.4106 - val_acc: 0.9038\n",
      "Epoch 6/100\n",
      "832/832 [==============================] - 0s 245us/step - loss: 0.3431 - acc: 0.9567 - val_loss: 0.2664 - val_acc: 0.9327\n",
      "Epoch 7/100\n",
      "832/832 [==============================] - 0s 233us/step - loss: 0.2278 - acc: 0.9700 - val_loss: 0.1735 - val_acc: 0.9231\n",
      "Epoch 8/100\n",
      "832/832 [==============================] - 0s 218us/step - loss: 0.1400 - acc: 0.9796 - val_loss: 0.1167 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "832/832 [==============================] - 0s 221us/step - loss: 0.0947 - acc: 0.9928 - val_loss: 0.0844 - val_acc: 0.9904\n",
      "Epoch 10/100\n",
      "832/832 [==============================] - 0s 233us/step - loss: 0.0757 - acc: 0.9916 - val_loss: 0.0490 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "832/832 [==============================] - 0s 247us/step - loss: 0.0439 - acc: 1.0000 - val_loss: 0.0372 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "832/832 [==============================] - 0s 248us/step - loss: 0.0331 - acc: 1.0000 - val_loss: 0.0257 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "832/832 [==============================] - 0s 232us/step - loss: 0.0369 - acc: 0.9964 - val_loss: 0.0387 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9efc104908>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epoch = 100\n",
    "# Fit the model\n",
    "model.fit(X_train, Y_train, epochs=nb_epoch, batch_size=32, verbose=1, validation_data=(X_val, Y_val), callbacks=[early_checker])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.0354232545082\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = y_classes = predictions.argmax(axis=-1)#model.predict_classes(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
